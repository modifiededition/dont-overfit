{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5b558a",
   "metadata": {},
   "source": [
    "# 1. Importing All required Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e701fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4ca66",
   "metadata": {},
   "source": [
    "# 2. Loading data-set and spliting into dependent and independent featues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b3549",
   "metadata": {},
   "source": [
    "## 2.1 Loading the train-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43e3bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target      0      1      2      3      4      5      6      7  ...  \\\n",
       "0   0     1.0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276  ...   \n",
       "1   1     0.0  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  ...   \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1 -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "\n",
       "[2 rows x 302 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f917de",
   "metadata": {},
   "source": [
    "## 2.2 Loading the test-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebec55e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.609</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.606</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-3.138</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      0      1      2      3      4      5      6      7      8  ...  \\\n",
       "0  250  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535 -0.129 -0.687  ...   \n",
       "1  251  0.776  0.914 -0.494  1.347 -0.867  0.480  0.578 -0.313  0.203  ...   \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0 -0.088 -2.628 -0.845  2.078 -0.277  2.132  0.609 -0.104  0.312  0.979  \n",
       "1 -0.683 -0.066  0.025  0.606 -0.353 -1.133 -3.138  0.281 -0.625 -0.761  \n",
       "\n",
       "[2 rows x 301 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73ad03",
   "metadata": {},
   "source": [
    "## 2.3 Splitting the train-data into dependent and inde-dependent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e4ebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data:  (250, 300)\n",
      "**************************************************\n",
      "Shape of target data:  (250,)\n",
      "**************************************************\n",
      "Unique values in the target:  [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns=[\"id\",\"target\"])\n",
    "y = df.target\n",
    "print(\"Shape of input data: \", x.shape)\n",
    "print(\"*\"*50)\n",
    "print(\"Shape of target data: \", y.shape)\n",
    "print(\"*\"*50)\n",
    "print(\"Unique values in the target: \", y.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e72ab8",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316a3800",
   "metadata": {},
   "source": [
    "## 3.1 Finding feature groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbff704",
   "metadata": {},
   "source": [
    "**So, the idea of this feature engineering technique is there are gropus of similar features, and it considers a good idea to generate new features based on these groups by calculating some statstic on these groups.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8883a950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAFNCAYAAACqtRxWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArZ0lEQVR4nO3deZhcZZn38e+vuxPWAAHClpVARBYFSQNhdARkEXiVgKCAjAMCRmZAhnfUAQWRF3AmjDouIwNGRJi5iLixRAZFYAR0IDHpCCQQkBjoTpMQQmggghI6fb9/nFOhUqnqrl5OVXXV73NdffXZz12V6jtPPedZFBGYmVk2mqodgJlZPXOSNTPLkJOsmVmGnGTNzDLkJGtmliEnWTOzDDnJZkjS4ZI6h/B6IWnPobperZF0kqTlkv4k6T3Vjsc2JmlS+hlsKbF/L0m/l7RW0oWVjq9WOcnWCEk3Sbo6w+sPhwT9NeCCiNg6In4/mAsNk9dbb/4JeCAiRkXEtwdzIUkPSDp3iOKqKidZqyUTgSeqHQSApOZqxzAM1dK/X9HSdlVEhH8G8QM8B3wBeBLoAn4AbJ7uOxzozDt2b+AB4BWSD+MJ6fYZwFvAOuBPwM9L3CuAC4FlwEvAV4GmvP1nA0vSOO4BJqbbH0rPfT29/qnAg8DJ6f73pfuPT9ePAh7t67rpvncC9wIvA08DH8vbdxNwLfDfwFpgHrBHkde1WRpXLsY/ptt3A34GrAaeBS7MO+dg4JH0vVwJfAcY2cvrPQv4bZH3c8+8WK8D7k7PO6q3+xd5DTcB/wH8Ir3n/wK7AN9M37engPfkHT+g15YX93nAM+m1rwVUIq4BXwtoJvl28RLJZ+789PiWIvf5H2A98Jf09b8j/Xf9GtABrAKuB7ZIjx8N3JW+/q50eVy67ysF1/oOMKnw3iR/S+emy2el7/k3SD6LV/d2/4rmiGonqeH+Q5JkFwPjge3Tf+ir032HkyZZYASwFPgiMBL4AEni2Svdf1PuvF7uFcCv0/tMAP6Q9yE7Mb3+3kALcBnwcMG5e+atXwn8e7r8ReCPwDV5+77V13WBrYDlwCfTfQemf5D75r2ml0n+0FuAW4Bb+3h9uaTXBLQBl6fv12SSP/QPpvunAtPS604i+U/gol5e71n0nWRfBd6b3nvL3u5fJPab0tc+FdicJOk8C/wtSbK6Gvj1EL62u4Dt0s/BauDYEnEN+Fokyfcp3v5s/5oSSTY9/gHSz2O6/k1gTnruKODnwL+k+3YATk7f51HAT4A7ernWpMJ7s2mS7QY+k77WLXq7f0VzRDUTVD38kCTZ8/LWj+ftktjhvJ1k/xp4gY1Lnj8ErkiXb6K8JHts3vrfA/eny78Azsnb1wS8wdul2cKkcyTweLr8S+BcYG66/iDwkb6uS1JC/E1BjN8Fvpz3mm4oeG+e6uP15ZLeIUBHwf4vAD8oce5FwO3FrpWun0XfSfY/8/b19/43Ad/LW/8MsCRv/V3AK0P42t6Xt/5j4JIyP69lX4vkP4r8z/YxlJlkAZF8I9gjb/+hwLMlzj0A6Cp2rXR9UuG92TTJduTt69f9s/ypnXqL4W153nI7yVfBQrsByyOip+DYsUN0r4nAtyR9PW+/0uu3F7nOI8A7JO1M8gE/Afh/knYkKXk+VMZ1JwKHSHolb18L8F956y/kLb8BbN3H68uZCOxWcO1m4DcAkt4B/BvQSlIaaiEpHQ5G/nvb6/1LWJW3/Oci67nXPhSvraz3dZDX2o1NP2/lGpPer03ShnBIXieStiT5an8sSdUBwChJzRGxvh/3yZcfa6/3ryQn2aExPm95ArCiyDErgPGSmvISbe4rPyT/S5d7r9zDhfx7LQe+EhG3lHORiHhDUhvwD8DiiFgn6WHgH0lK4i/1dV1JE4EHI+LoMmPvj+UkpY4pJfZfB/weOD0i1kq6CDill+u9TvJHB4CkXYock/9v0Nf9B2OoX1tvBnOtlWz62S7XSyT/sewbEc8X2f9ZYC/gkIh4QdIBaZy5jFj49/B6+ntL4LV0ufDfMP+cvu5fMW5dMDTOlzRO0vYk9Zs/KnLMPJIPyj9JGiHpcODDwK3p/lUkdXN9+byk0ZLGkyTI3L2uB74gaV8ASdtK+mjeecWu/yBwQfobkq9f+et9XfcuktLwJ9LXNELSQZL2LuN19OV3wGuSLpa0haRmSftJOijdP4rkj+1Pkt4J/F3B+YWv9zFgX0kHSNocuGKQ9x+Mwb62/hjMtX4MXJh+tkcDl5R7YlqQ+B7wDUk7AUgaK+mDeXH9GXgl/bv5csElNvr3i4jVwPPA36Tv19nAHoO4f8U4yQ6N2cCvSB5eLCN5yLGRiFhH8pX8OJL/Zf8D+NuIeCo95PvAPpJekXRHL/e6k+Tr3qMkT+2/n17/duAa4FZJr5E8jDsu77wrgJvT638s3fYgyYf9oRLrvV43ItaS1NOdRlKifiE9drNe4i9L+pXxwyRVGc+SvGc3ANumh3wO+DjJw8Pvsel/bBu93oj4A8kDvftInqT/dpD3H7AheG39MZhrfY+kNcljwELgtn7e+2KSh6Zz08/OfSSlV0geSm1B8trnkjwXyPct4BRJXZJybW4/BXweWAPsCzw8iPtXTK6phg2QpOdIKt/vq3YsZlZ7XJI1M8uQk6yZWYZcXWBmliGXZM3MMuQka2aWoYbqjLDjjjvGpEmTqh2GmdWZtra2lyJiTLF9DZVkJ02axIIFC6odhpnVGUkluxxXtbpA0rGSnpa0VNImvUkknSHp8fTnYUn7l3uumVktqFqSTQdFvpak99A+wOmS9ik47FngsIh4N3AVMKsf55qZVV01S7IHA0sjYlna5fRWYHr+ARHxcER0patzgXHlnmtmVguqmWTHsvHQZJ30PuzfOSRjmw7kXDOzqqjmgy8V2Va0Z4SkI0iS7PsGcO4MkuldmDChPyO1mZkNXjVLsp1sPFblOIqMwyrp3SQjFE2PiDX9ORcgImZFRGtEtI4ZU7SFhZlZZqqZZOcDUyTtLmkkyXB5c/IPkDSBZHi1T6RD1ZV9rplZLahadUFEdEu6gGS8ymbgxoh4QtJ56f7rSSaa2wH4j3QKie60VFr03Kq8EDOzXjTUADGtra3hzghmVkpbexdzl61h2uQdmDpxdN8npCS1RURrsX0N1ePLzKyUtvYuzrhhLuu6exjZ0sQt507rV6ItxQPEmJkBc5etYV13Dz0Bb3X3MHfZmr5PKoOTrJkZMG3yDoxsaaJZMKKliWmTdxiS67q6wMwMmDpxNLecO21AdbK9cZI1M0tNnTh6yJJrjqsLzMwy5CRrZpYhJ1kzsww5yZqZZchJ1swsQ06yZmYZcpI1M8uQk6yZWYacZM3MSAaIufbXS2lr7+r74H5wjy8za3hZjcAFLsmamWU2Ahc4yZqZZTYCF7i6wMwssxG4wEnWzAzIZgQucHWBmVmmnGTNzDLkJGtmhtvJmpllpm7byUo6VtLTkpZKuqTI/ndKekTSm5I+V7DvOUmLJD0qaUHlojazepNlO9mqlWQlNQPXAkcDncB8SXMi4sm8w14GLgROLHGZIyLipUwDNbO6l2sn+1Z3T121kz0YWBoRywAk3QpMBzYk2Yh4EXhR0v+pTohm1gjqtZ3sWGB53noncEg/zg/gV5IC+G5EzCp2kKQZwAyACRMmDDBUM6t39dhOVkW2RT/Of29EHAgcB5wv6f3FDoqIWRHRGhGtY8aMGUicZmYDVs0k2wmMz1sfB6wo9+SIWJH+fhG4naT6wcysplQzyc4HpkjaXdJI4DRgTjknStpK0qjcMnAMsDizSM2srmXVRhaqWCcbEd2SLgDuAZqBGyPiCUnnpfuvl7QLsADYBuiRdBGwD7AjcLskSF7D7Ij4ZRVehpkNc1m2kYUqd0aIiLuBuwu2XZ+3/AJJNUKh14D9s43OzBpBsTayQ5lk3a3WzBpalmPJgrvVmpnxkQPHofT3UDfjcpI1s4ZVWB/7kQOL1U4OjqsLzKxhZTlmQY6TrJk1rKzrY8HVBWbWwLIcsyDHSdbMGlpWYxbkuLrAzBpWlj29clySNbOGlHVPrxyXZM2sIVWiZQE4yZpZg6pEywJwdYGZNbAse3rlOMmaWcOpRE+vHFcXmFnDqVR9LLgka2YNaPSWI2mSgMi0PhZckjWzBjN7XgeX37mY9T1Bk8TlH9o3084ILsmaWcNoa+/i8jsX092TzNnaE0HXG+syvadLsmbWMG5b2LkhwQI0SZlWFYCTrJk1iNnzOvjhvI6Ntp37vt0zrSoAJ1kzawC5aoKegu2jthiR+b2dZM2s7s1dtob1edUEACMzblWQ4wdfZlb3pk3egc1GNLHurR4kOHLvnfn0YXtkXlUAVU6yko4FvgU0AzdExMyC/e8EfgAcCFwaEV8r91wzs5xKDM5dStWSrKRm4FrgaKATmC9pTkQ8mXfYy8CFwIkDONfMbIOsB+cupZp1sgcDSyNiWUSsA24FpucfEBEvRsR84K3+nmtmVguqmWTHAsvz1jvTbVmfa2YNphIzIJRSzTpZFdkWRbYN6lxJM4AZABMmTCjz8mZWLyo1A0Ip1SzJdgLj89bHASuG+tyImBURrRHROmbMmAEFambD120LO3nzrcqMuFVMNZPsfGCKpN0ljQROA+ZU4FwzaxCz53Vw6+86NnzNbW6uTNvYfFWrLoiIbkkXAPeQNMO6MSKekHReuv96SbsAC4BtgB5JFwH7RMRrxc6tygsxs5o0e14Hl96xiEgzrIBTpmY3A0IpVW0nGxF3A3cXbLs+b/kFkqqAss41M2tr7+L6B//IfU+u2uhBTVOTODnDGRBKcY8vMxv22tq7+NnCTpauWsuC9i56ijwG/8A7d6pKO1knWTMb1mbP6+CyOxYVTaw5Lc3ivMP2qFxQ+feuyl3NzIbA7HkdXHr7opJtP5sER1VwnIJinGTNbFjJrxqY395VNMHWQnLNcZI1s5q3UWJ9rnhihaQFwdH71EZyzXGSNbOaNnteB1+6YxHre6lzrcXkmuMka2Y1q5yHWs1N4qrp+/HxQ2qz27yTrJnVpL4SbC2XXvM5yZpZzSnsrQVJUj1o0mi223IkY0ZtxkcOrHzvrYFwkjWzmtLW3sWXChOs4CsnvqtmqwR644kUzaymzF22ZpOHXEftvfOwTLDgJGtmNaStvYtHl79CU96I0dXsrTUUXF1gZlWXG9Tl/iWrNjzoqqUOBYPhJGtmVVWqHWwE7D9+u2GdYMHVBWZWRW3tXVx+5+KiHQ1GtFR+gO0suCRrZlUzd9ka1hc0hK2XaoIcJ1kzq4q29i4eePrFjcYhOHjSaC4+bu+6SK45TrJmVnFt7V2cPusR1uXVEwg4bK/qDKydJdfJmlnF3bawc6MEC8kYBPVQB1vISdbMKqqtvYufLFi+0bbmJnHl9P3qrhQLri4wswq7bWEnb+WVYvcfty2Xf3jfukyw4JKsmVXQzLuXMHtex4aHXSNbmuo6wYJLsmaWodyMBi+tfZPlL7/BkhfWbrT/lKnDYyStwahqkpV0LPAtoBm4ISJmFuxXuv944A3grIhYmO57DlgLrAe6I6K1gqGbWR+KtSDI1yQ4+cBxFY6q8qqWZCU1A9cCRwOdwHxJcyLiybzDjgOmpD+HANelv3OOiIiXKhSymfVDsRYE+Wb89eS6L8VCdetkDwaWRsSyiFgH3ApMLzhmOvCfkZgLbCdp10oHamb9M3teB7f+rqPoPgnOe/9kLjl+7wpHVR3VrC4YC+S34+hk41JqqWPGAiuBAH4lKYDvRsSsDGM1sxLy610BXnlj3SYzyu45Zismj9l6WM1oMFSqmWRVZFvhd4vejnlvRKyQtBNwr6SnIuKhTW4izQBmAEyYMDwH/TWrFeUk1ELNTeKaU/ZvqMSar5pJthMYn7c+DlhR7jERkfv9oqTbSaofNkmyaQl3FkBra2tvnwUzK6GtvYuZv1jC/Oe6+n3uB95Zf11l+6OsJCtpLDAx//hipcZ+mg9MkbQ78DxwGvDxgmPmABdIupWkKuHViFgpaSugKSLWpsvHAFcOMh4zK2L2vA4uu30RPQM4d7jPajAU+kyykq4BTgWeJGkuBclX9kEl2YjolnQBcA9JE64bI+IJSeel+68H7iZpvrWUpAnXJ9PTdwZuT1p40QLMjohfDiYeM0vkVwm88sY65rf3Xh2Qkz+bLNCQ9a/FKKL3t0/S08C7I+LNyoSUndbW1liwYEG1wzCrWbPndXDZHYvo6SOr7r3LKMZvv+WG9UZPqJLaSrXVL6e6YBkwAhj2SdbMNpUruS5dtbbPh1h77rQ1Z79392E7c2w1lJNk3wAelXQ/eYk2Ii7MLCozq4iZdy/huw8t67M6oLlJXDV9PyfXASgnyc5Jf8xsGCtsflVsLIF8uTrWKTuPauiqgMHqM8lGxM2VCMTMhk5/E2q+eptjq9rKaV0wBfgXYB9g89z2iJicYVxmNgCDac+69y6jOHDiaJdah1g51QU/AL4MfAM4gqQZVbGeWGZWRQNtzyrBp/+6ccYSqLRykuwWEXG/JEVEO3CFpN+QJF4zq7K29i6uf/CP3LdkVVntWfObXzV606tKKCfJ/kVSE/BM2nngeWCnbMMys77kkuv9S1aVbNeaS6ivvLGON7t7OPWgCW4hUGHlJNmLgC2BC4GrSKoMzswwJjPrQ1+dBtyetXaU07pgPkBSWxCf7Ot4M8vW7HkdXHr7oqJVA27PWnvKaV1wKPB9YGtggqT9gU9HxN9nHZxZIyscQ+Dl19cxormJp1atLZpgj9nHza5qUTnVBd8EPkjaISEiHpP0/iyDMmtk5dS15msSXH3iu1x6rVFlDXUYEcvTEa9y1pc61swGpr9tXAUc7dJrzSsnyS6X9FdASBpJ8gBsSbZhmdW32fM6+NH8DjZraWK7LUeWNcNAPte9Dh/lJNnzSKblHksyU8GvgPOzDMqsXuS++j+7+k9sv9VItttyZL+7uLampdSXX1/H9luN9FgCw0w5rQteAs6oQCxmdWNDB4En8zoIrH69X9c4eNJoLj5ubyfTYa6c1gW7A58BJrHx9DMnZBeW2fA1e14HX7pjEesHMKOcgD3cxrWulFNdcAdJE66fw4Cm+TGre7mS65MrXmXFK38pu27VXVzrX1ndaiPi25lHYjZMtbV3cep3H6a7RBFEwG6jt2Dstpt7/qsGVE6S/ZakL5M88MqfGWFhZlGZDQO5zgK/e/blognWTawMykuy7wI+AXyAt6sLIl03ayi5xPr79q5eWwi4g4DllJNkTwImR8S6rIMxqyWFza8AFrR39doLa/stR9A6aXuXXm2DcpLsY8B2wIvZhmJWXYVjBWzUOaCM5lcjW5r43pkHObnaRspJsjsDT0maz8Z1soNuwiXpWJKODs3ADRExs2C/0v3Hk8yae1auLrivc836o9xZW4vxtC3Wm3KSbCYzIEhqBq4FjibpSTZf0pyIeDLvsOOAKenPIcB1wCFlnmtW1GAmGYSkvnWvnUcxsqXJg2Bbn8rp8fVgRvc+GFgaEcsAJN0KTAfyE+V04D8jIoC5kraTtCtJx4i+zjXbRF+DXRcqbH7lplfWX2WNwpWRscDyvPVOktJqX8eMLfNcM+DtkuvSVWvLGoQl10HACdWGQjWTbLEZbws//6WOKefc5ALSDGAGwIQJ/lrXaPrTxdWztloWykqykrYAJkTE00N4705gfN76OGBFmceMLONcACJiFjALoLW1dSDPNWwYKmdsVgEHTRrtagDLVDkDxHwY+BpJYttd0gHAlUPQumA+MCUdgOZ54DTg4wXHzAEuSOtcDwFejYiVklaXca41kF6bXxVoEhy1t3tiWWWUU5K9guQh1QMAEfGopEmDvXFEdKdTjN9D0gzrxoh4QtJ56f7rgbtJmm8tJWnC9cnezh1sTDb8FB1SsISDJ432WKxWceUk2e6IeLVg+pkhERF3kyTS/G3X5y0HJQYIL3auNZa29i5On/UI68qocD3v/a5rteooJ8kulvRxoFnSFJLpZx7ONiyz0vIHZuktwXpsVqsF5STZzwCXkvT2mk3yFf3qLIMyK6Y/D7NcLWC1otckm/asmhMRR5EkWrOqmD2vg8tuX1Ry1Pg9x2zFIZN3cGK1mtNrko2I9ZLekLRtRLxaqaDMoKATQXvp1gIjW5q45pT9nVytJpU1MwKwSNK9wIahiCLiwsyisoZWTrUAeGAWGx7KSbL/nf6YZa6vagGAPf0wy4aRcgaIubkSgVjjKrdaoLlJXDV9PydXG1bK6fH1LEXGBYiIyZlEZA2lrb2LU2c9QncvTbFcLWDDWTnVBa15y5sDHwW2zyYcazS3LewsmWBdLWD1oJzqgjUFm74p6bfA5dmEZI2irb2LecsKP16uFrD6Uk51wYF5q00kJdtRmUVkdatwEJfCSQk9hbbVo3KqC76et9wNPAt8LJtwrN70Z8Ds0w+ZwD+f9K6KxWZWCeUk2XNy07zkpEMMmm0iP6k+/8qfWfHKX8qanHBkSxMnHzgu8/jMKq2cJPtT4MAi26YOfTg2nPVnVKwcj+1q9a5kkpX0TmBfYFtJH8nbtQ1JKwOzDdrau7jy50+UlWA9iIs1kt5KsnsBHwK2Az6ct30t8KkMY7JhIjdg9pMrXu21WsDTvFgjK5lkI+JO4E5Jh0bEIxWMyWpYuQ+yxm63OVuMaGbymK1dFWANrZw62d9LOp+k6mBDNUFEnJ1ZVFZzZs/r4MbfLuOPq1/v80HWyJYmvn36gU6sZpSXZP8LeAr4IHAlcAawJMugrDbkSq2/b+9iyQtr+zze7VzNNlVOkt0zIj4qaXpE3CwpNzuC1bHZ8zr40h2L6Os5loDdRm/Bvrtu4+RqVkQ5Sfat9PcrkvYDXgAmZRaRVU25JVe3DjArXzlJdpak0cCXgDnA1njcgrrQVzfXYg6eNJqLj9vbidWsTOUMEHNDuvggMCTDG0raHvgRSYn4OeBjEbHJMPiSjgW+BTQDN0TEzHT7FSTNyFanh34xnSLcyjR7XgeX3bGoz6QKSWJ1qdVsYMoZIGZn4J+B3SLiOEn7AIdGxPcHcd9LgPsjYqakS9L1iwvu2wxcCxwNdALzJc2JiCfTQ74REV8bRAwNa/a8Di69fVFZ3V3Pe/9kLjl+78xjMqtXTWUccxPJg67d0vU/ABcN8r7TgdyMCzcDJxY55mBgaUQsi4h1wK3peTYIbe1dXH7n4pIJtknJINn7j9uWfz7pXU6wZoNUTp3sjhHxY0lfAIiIbknrB3nfnSNiZXq9lZJ2KnLMWGB53noncEje+gWS/hZYAHy2WHWDbSzX9bW7oI7AD7LMslNOkn1d0g6kU9BImgb0OT24pPuAXYrsurTM2FRkWy47XAdcla5fRTIcY9HOEZJmADMAJkxo3EGgiw3e4sFZzLJXTpL9R5JWBXtI+l9gDHBKXydFxFGl9klaJWnXtBS7K/BikcM6gfF56+OAFem1V+Vd63vAXb3EMQuYBdDa2lr+8FB1pK29i4t/9vgmg7ecdrDHbzXLWm+jcE2IiI6IWCjpMJIBYwQ8HRFvlTqvTHOAM4GZ6e87ixwzH5iSjl37PHAa8PE0tl1z1Q3AScDiQcZTt9rauzj1uw/TXTDHtsdvNauM3kqyd/D2OLI/ioiTh/C+M4EfSzoH6CCZnBFJu5E01To+rfu9gOShWzNwY0Q8kZ7/r5IOIKkueA749BDGNuzlt39d9tLrmyTYXbbZjGvPmOoqArMK6C3J5teJDun03+nkjEcW2b4COD5v/W5gk/avEfGJoYynXrS1dzHzF0uY/1zvzwAvPPIdTrBmFdJbko0Sy1YjCnts9TWH1i7bbMaFR77Ds8CaVVBvSXZ/Sa+RlGi3SJdJ1yMitsk8Oiuprb2LU2c9QneZU72MbGlyFYFZFfQ2aHdzJQOx/rltYWefCXbvXUYxfvstPRuBWRWV04TLatDqtW8W3S5gj5225uz37u5qAbMa4CQ7zOTm1bp/yYamwu6xZVbDnGSHkWIDaQs4/RB3KjCrVU6yw0Cu9HrfklVEQTVsc5PcqcCshjnJ1rjexn1tbhJXTt/P1QNmNcxJtoaVGvfVExaaDR9OsjUm18Fg6aq1zG/ftHOBBF858V1uOWA2TDjJ1pC+ZohtElztBGs2rDjJ1oi29i6+dOfiognW1QNmw5eTbA3Ijfe6vsjTreYmcdX0/Vx6NRumnGSrKL9jQWF+HTt6Cw5/xxh3LjAb5pxkq6TYdDA5zYJvn/YeJ1ezOuAkWyVzl63hrWIJNq0ecII1qw9OslUyesuRNIkND7o8qaFZfXKSrYK29i6u+PkTrA8nV7N611TtABrNhplj04m3egLGjNrMCdasTrkkW0GlHnZ5bh+z+uWSbAXdtrBzkwTbLDyKllkdc0m2QmbP6+DW33VstM0tCczqn5NsBbS1d3F5QZfZ/cdty+Uf3tcJ1qzOVaW6QNL2ku6V9Ez6u2imkXSjpBclLR7I+bXitoWddOd16WppkhOsWYOoVp3sJcD9ETEFuD9dL+Ym4NhBnF91be1d/GTB8g3rHmjbrLFUK8lOB25Ol28GTix2UEQ8BLw80PNrwdxlazaUYgWcetB4D/Zi1kCqlWR3joiVAOnvnSp8fsUkPbtEk2CzEU1uSWDWYDJ78CXpPmCXIrsuzeqeJeKYAcwAmDChsiXItvYurrzrCdb3BM1N4vIPuR7WrNFklmQj4qhS+yStkrRrRKyUtCvwYj8vX/b5ETELmAXQ2tpa0Xb/c5etYV13D5HEQdcb6yp5ezOrAdWqLpgDnJkunwncWeHzM9fW3sWjy18BkrrY5uYmpk3eoaoxmVnlVSvJzgSOlvQMcHS6jqTdJN2dO0jSD4FHgL0kdUo6p7fza0Wu++y9TyaDcQfQE+48a9aIqtIZISLWAEcW2b4COD5v/fT+nF8rio0Vu359MHfZGtfJmjUYj12QgdxYsflGtLi6wKwRuVvtEJs9r4PL71xMTySDv0ydOJopO4/yXF1mDcpJdoi0tXcx8xdLmP9c14ZtARy2106cf8Se1QvMzKrKSXYIzJ7XwWW3L6KnYHuT5CoCswbnOtlBmj2vg8vu2DTBCjxGgZk5yQ5GbgjDniKtsz79/skeo8DMXF0wGHOXrWF9QYbdc6etOfu9uzvBmhngJDso0ybvwGYjmlj3Vg9N6RCGTq5mls9JdhCmThzNLedOY+6yNUybvIPrX81sE06ygzR14mgnVzMryQ++zMwy5JLsALS1d/GzhZ28tPZNxozazL25zKwkJ9l+yo2wtS5vAJiftHXyw09Nc6I1s024uqCfio2w9VZ3D3OXralSRGZWy5xk+2na5B0Y0bzxEFseYcvMSnF1QT9NnTiaK07Yjx/N72CzliaPsGVmvXKS7ae3hzIMRrY0cfFxezvBmllJri7oh9xYBd09QU/AOtfFmlkfnGT7oXCsAg9laGZ9cZItU2722aYmIaAlHavAVQVm1hvXyZahsG1ssweDMbMyuSRbhsK2sT09Qdcb66oYkZkNF06yZSicfdbtYs2sXFVJspK2l3SvpGfS30UrNiXdKOlFSYsLtl8h6XlJj6Y/x2cVa1t7F1fe9cSG2WeP2Wdnd6E1s7JVqyR7CXB/REwB7k/Xi7kJOLbEvm9ExAHpz90ZxAjAbQs7efOtHnKVBfuP384J1szKVq0kOx24OV2+GTix2EER8RDwcoVi2kRbexc/WbB8Q4JtbnY1gZn1T7WS7M4RsRIg/b3TAK5xgaTH0yqFTIqWc5etoTttFyvglKnuPmtm/ZNZkpV0n6TFRX6mD8HlrwP2AA4AVgJf7yWOGZIWSFqwevXqft1k2uQdGNnSRLNgsxFNnHzguMHEbGYNSBFF5rPO+qbS08DhEbFS0q7AAxGxV4ljJwF3RcR+A9mfr7W1NRYsWNCvWNvauzyHl5n1SlJbRLQW21etzghzgDOBmenvO/tzsqRdc9UNwEnA4t6OHwzP4WVmg1GtOtmZwNGSngGOTteRtJukDS0FJP0QeATYS1KnpHPSXf8qaZGkx4EjgP9b2fDNzMpTlZJsRKwBjiyyfQVwfN766SXO/0R20ZmZDR33+DIzy5CTbC/a2ru49tdLaWvvqnYoZjZMeRSuEtrauzjjhrms6+5hZEsTt5zrrrRm1n8uyZYwd9ka1nX30BOejdbMBs5JtoT8jggedcvMBsrVBSVMnTiaW86d5o4IZjYoTrK9cEcEMxssVxeYmWXISdbMLENOsmZmGXKSNTPLkJOsmVmGnGTNzDLkJGtmliEnWTOzDDnJmpllyEnWzCxDTrJmZhlykjUzy5CTrJlZhpxkzcwy5CRrZpYhJ1kzswxVJclK2l7SvZKeSX9vMjK2pPGSfi1piaQnJP1Df843M6sF1SrJXgLcHxFTgPvT9ULdwGcjYm9gGnC+pH36cf6geUpwMxusak0/Mx04PF2+GXgAuDj/gIhYCaxMl9dKWgKMBZ4s5/zB8pTgZjYUqlWS3TlNorlkulNvB0uaBLwHmNff8yXNkLRA0oLVq1eXHaCnBDezoZBZSVbSfcAuRXZd2s/rbA38DLgoIl7rbxwRMQuYBdDa2hrlnpebEvyt7h5PCW5mA5ZZko2Io0rtk7RK0q4RsVLSrsCLJY4bQZJgb4mI2/J2lXX+YHhKcDMbCtWqLpgDnJkunwncWXiAJAHfB5ZExL/19/yhMHXiaM4/Yk8nWDMbsGol2ZnA0ZKeAY5O15G0m6S702PeC3wC+ICkR9Of43s738ys1lSldUFErAGOLLJ9BXB8uvxbQP0538ys1rjHl5lZhpxkzcwy5CRrZpYhJ1kzsww5yZqZZchJ1swsQ06yZmYZUkTZ3fmHPUmrgfZ+nrYj8FIG4Qw1xzn0hkuswyVOGD6x9jfOiRExptiOhkqyAyFpQUS0VjuOvjjOoTdcYh0uccLwiXUo43R1gZlZhpxkzcwy5CTbt1nVDqBMjnPoDZdYh0ucMHxiHbI4XSdrZpYhl2TNzDLU0Em21LTjkr4q6SlJj0u6XdJ26fYRkm6WtCg95wsVjPVGSS9KWpy37QpJzxeOtytph/R1/UnSdyoVYy9x7i/pkfR9+7mkbaodZyFJ20n6afrvvkTSoaXe3wrHVeozelX6+XxU0q8k7ZZ3zrvT9/uJ9D3fvApx75X3vj0q6TVJF5X626prEdGwP8CuwIHp8ijgD8A+wDFAS7r9GuCadPnjwK3p8pbAc8CkCsX6fuBAYHHetiuAzxU5divgfcB5wHcq/J4Wi3M+cFi6fDZwVbXjLBL3zcC56fJIYLtS72+F4yr1Gd0m75gLgevT5RbgcWD/dH0HoLnKr6EZeAGYWOpvq55/GrokGxErI2JhurwWWAKMjYhfRUR3ethcYFzuFGArSS3AFsA6oN+TOw4w1oeAl8s89vVIBj3/S7ZRFb13sTj3Ah5Kl+8FTk6PrVqc+dKS9ftJpjsiItZFxCvVjCmnl89o/uduK5LPJiRJ7PGIeCw9Z01ErK9kzEUcCfwxItp7+duqWw2dZPMVmXY852zgF+nyT4HXgZVAB/C1iCgr8WXogvSr142SanUyssXACenyR4HxVYylmMnAauAHkn4v6QZJW6X7aub9LfyMSvqKpOXAGcDl6WHvAELSPZIWSvqnqgS7sdOAHxbZnv+3VbecZCk97bikS4Fu4JZ008HAemA3YHfgs5ImVzjcfNcBewAHkCT+r1cxlt6cDZwvqY3kK++6KsdTqIWkiuO6iHgPyX+kl1BD72+xz2hEXBoR40k+nxekh7aQVMGckf4+SVLVpmqSNJLkP9ifFGwv/NuqWw2fZEtNOy7pTOBDwBmRViCR1Mn+MiLeiogXgf8FqtZFMCJWRcT6iOgBvkfyn0DNiYinIuKYiJhKUqL5Y7VjKtAJdEZE7lvMT0nqQWvi/S31Gc0zm7QKhuS1PBgRL0XEG8DdJP+BVMtxwMKIWJXbUOJvq241dJItNe24pGOBi4ET0g9qTgfJ7LlKv05OA56qZMz5JO2at3oSydfymiNpp/R3E3AZcH11I9pYRLwALJe0V7rpSODJWnh/e/mMTsk77ATe/hzeA7xb0pbps4PDgCcrFW8Rp5NXVdDL31bdaujOCJLeB/wGWAT0pJu/CHwb2AxYk26bGxHnpV/ZfkDydFfADyLiqxWK9YfA4SSjA60CvpyuH0Dy0OM54NMRsTI9/jlgG5In5a8Ax0RE5n9sJeLcGjg/PeQ24Au5Eky14iwk6QDghjSOZcAnST4HB1Dk/a1gXKU+o+eQPFDsIRlZ7ryIeD4952+AL6Rx3x0RVamXlbQlsByYHBGvptuWUuRvqxrxVUpDJ1kzs6w1dHWBmVnWnGTNzDLkJGtmliEnWTOzDDnJmpllyEnW6o6k9QUjQE0awDVOlLRPBuFZg2mpdgBmGfhzRBwwyGucCNxFPxryS2rJG/zEDHBJ1hqEpKmSHpTUlg6esmu6/VOS5kt6TNLP0p5Sf0XSi+qraUl4D0kPSGpNz9kx7USBpLMk/UTSz4FfSdoqHUxmfjrYzPRqvWarDU6yVo+2yKsquD3t+//vwCnp+Ak3Al9Jj70tIg6KiP1JhhE8JyIeBuYAn4+IAyKir7EWDgXOjIgPAJcC/xMRBwFHkCTqrXo92+qaqwusHm1UXSBpP2A/4N5kKACaSUbVAthP0tUkg3RvTdL3v7/uzRvy8hjgBEmfS9c3ByaQJHBrQE6y1ggEPBERhxbZdxNwYkQ8JuksknEXiunm7W9+hdO5vF5wr5Mj4ukBR2t1xdUF1gieBsZIOhQ2zNW2b7pvFLAyrVI4I++ctem+nOeAqenyKb3c6x7gM+noWUh6z+DDt+HMSdbqXkSsI0mM10h6DHgU+Kt095dIZhq4l42HrbwV+Hz68GoP4GvA30l6mGSEsVKuAkYAjyuZTPKqoXwtNvx4FC4zswy5JGtmliEnWTOzDDnJmpllyEnWzCxDTrJmZhlykjUzy5CTrJlZhpxkzcwy9P8Bb5+EkWwOVTEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "x.mean().sort_values().plot(style = \".\")\n",
    "plt.title(\"plot between feature mean and feature\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Feature mean\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32c88cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74    -0.117244\n",
       "119   -0.116228\n",
       "66    -0.114680\n",
       "147   -0.113868\n",
       "175   -0.113800\n",
       "         ...   \n",
       "251    0.092040\n",
       "233    0.092460\n",
       "34     0.093852\n",
       "186    0.095228\n",
       "282    0.098476\n",
       "Length: 277, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((x.mean().sort_values()[11:288]))\n",
    "\n",
    "## first group: 11:288\n",
    "## second group: 2:11\n",
    "## third group: 288:293\n",
    "## fourth group: 293: 295"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528662b7",
   "metadata": {},
   "source": [
    "### Observation(s):\n",
    "- There is one big group of 277 similar features observed in the above plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19e8e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  45]\n",
      " [  1 101]\n",
      " [  2  22]\n",
      " [  3  40]\n",
      " [  4  42]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(x)\n",
    "unique, counts = np.unique(kmeans.labels_, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94ba6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engg(df,data):\n",
    "    \"\"\"\n",
    "    Genrating new features by computing stats on the feature group/ similar features.\n",
    "    \"\"\"\n",
    "    statistics  = pd.DataFrame()\n",
    "    \n",
    "    statistics[\"mean\"] = df.mean(axis=1)\n",
    "    statistics[\"kurt\"] = df.kurt(axis=1)\n",
    "    statistics[\"mad\"] =  df.mad(axis=1)\n",
    "    statistics[\"median\"] =  df.median(axis=1)\n",
    "    statistics[\"max\"] =  df.max(axis=1)\n",
    "    statistics[\"min\"] =  df.min(axis=1)\n",
    "    statistics[\"skew\"] =  df.skew(axis=1)\n",
    "    statistics[\"sem\"] =  df.sem(axis=1)\n",
    "    \n",
    "    # clustering the whole data into 5 clusters and using cluster values as FE.\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0).fit(df)\n",
    "    statistics[\"cluster_values\"] = kmeans.labels_\n",
    "    \n",
    "    # computing min, max and mean of instances to their 5-NN as FE\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    neigh = NearestNeighbors()\n",
    "    neigh.fit(df)\n",
    "    dists, _ = neigh.kneighbors(df, n_neighbors=5)\n",
    "    dists = np.delete(dists, 0, 1)\n",
    "    statistics['minDist'] = dists.mean(axis=1)\n",
    "    statistics['maxDist'] = dists.max(axis=1)\n",
    "    statistics['meanDist'] = dists.min(axis=1)\n",
    "\n",
    "    X = pd.concat([data, statistics], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e006b643",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>mad</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>sem</th>\n",
       "      <th>cluster_values</th>\n",
       "      <th>minDist</th>\n",
       "      <th>maxDist</th>\n",
       "      <th>meanDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-2.246</td>\n",
       "      <td>1.825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910098</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>2.929</td>\n",
       "      <td>-2.851</td>\n",
       "      <td>0.016958</td>\n",
       "      <td>0.066556</td>\n",
       "      <td>2</td>\n",
       "      <td>22.946820</td>\n",
       "      <td>23.109234</td>\n",
       "      <td>22.616754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774677</td>\n",
       "      <td>0.066</td>\n",
       "      <td>2.907</td>\n",
       "      <td>-2.771</td>\n",
       "      <td>-0.132574</td>\n",
       "      <td>0.058468</td>\n",
       "      <td>2</td>\n",
       "      <td>21.238207</td>\n",
       "      <td>21.376524</td>\n",
       "      <td>20.940463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276 -2.246  1.825  ...   \n",
       "1  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  0.004 -0.291  ...   \n",
       "\n",
       "        mad  median    max    min      skew       sem  cluster_values  \\\n",
       "0  0.910098  -0.057  2.929 -2.851  0.016958  0.066556               2   \n",
       "1  0.774677   0.066  2.907 -2.771 -0.132574  0.058468               2   \n",
       "\n",
       "     minDist    maxDist   meanDist  \n",
       "0  22.946820  23.109234  22.616754  \n",
       "1  21.238207  21.376524  20.940463  \n",
       "\n",
       "[2 rows x 312 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_1 = feature_engg(x.loc[:,list(x.mean().sort_values()[11:288].index)],x)\n",
    "fe_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af2868f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>mad</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>sem</th>\n",
       "      <th>cluster_values</th>\n",
       "      <th>minDist</th>\n",
       "      <th>maxDist</th>\n",
       "      <th>meanDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>1.291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794220</td>\n",
       "      <td>0.262</td>\n",
       "      <td>3.472</td>\n",
       "      <td>-2.174</td>\n",
       "      <td>0.102823</td>\n",
       "      <td>0.058687</td>\n",
       "      <td>1</td>\n",
       "      <td>20.065607</td>\n",
       "      <td>20.316209</td>\n",
       "      <td>19.764365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.203</td>\n",
       "      <td>1.356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850657</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>2.639</td>\n",
       "      <td>-3.138</td>\n",
       "      <td>0.041626</td>\n",
       "      <td>0.062853</td>\n",
       "      <td>4</td>\n",
       "      <td>20.888684</td>\n",
       "      <td>21.067379</td>\n",
       "      <td>20.701981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535 -0.129 -0.687  1.291  ...   \n",
       "1  0.776  0.914 -0.494  1.347 -0.867  0.480  0.578 -0.313  0.203  1.356  ...   \n",
       "\n",
       "        mad  median    max    min      skew       sem  cluster_values  \\\n",
       "0  0.794220   0.262  3.472 -2.174  0.102823  0.058687               1   \n",
       "1  0.850657  -0.052  2.639 -3.138  0.041626  0.062853               4   \n",
       "\n",
       "     minDist    maxDist   meanDist  \n",
       "0  20.065607  20.316209  19.764365  \n",
       "1  20.888684  21.067379  20.701981  \n",
       "\n",
       "[2 rows x 312 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fe_1 = feature_engg(test_df.drop(columns=[\"id\"]).loc[:,list(x.mean().sort_values()[11:288].index)],test_df.drop(columns=[\"id\"]))\n",
    "test_fe_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9664c011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>mad</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>sem</th>\n",
       "      <th>cluster_values</th>\n",
       "      <th>minDist</th>\n",
       "      <th>maxDist</th>\n",
       "      <th>meanDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-2.246</td>\n",
       "      <td>1.825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892740</td>\n",
       "      <td>-0.0505</td>\n",
       "      <td>2.929</td>\n",
       "      <td>-2.851</td>\n",
       "      <td>0.037492</td>\n",
       "      <td>0.062883</td>\n",
       "      <td>1</td>\n",
       "      <td>23.642639</td>\n",
       "      <td>23.882662</td>\n",
       "      <td>23.158032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788005</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>2.907</td>\n",
       "      <td>-2.771</td>\n",
       "      <td>-0.214699</td>\n",
       "      <td>0.056917</td>\n",
       "      <td>3</td>\n",
       "      <td>22.462934</td>\n",
       "      <td>22.635361</td>\n",
       "      <td>22.343140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276 -2.246  1.825  ...   \n",
       "1  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  0.004 -0.291  ...   \n",
       "\n",
       "        mad  median    max    min      skew       sem  cluster_values  \\\n",
       "0  0.892740 -0.0505  2.929 -2.851  0.037492  0.062883               1   \n",
       "1  0.788005  0.0745  2.907 -2.771 -0.214699  0.056917               3   \n",
       "\n",
       "     minDist    maxDist   meanDist  \n",
       "0  23.642639  23.882662  23.158032  \n",
       "1  22.462934  22.635361  22.343140  \n",
       "\n",
       "[2 rows x 312 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_2 = feature_engg(x,x)\n",
    "fe_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0576a28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>mad</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>sem</th>\n",
       "      <th>cluster_values</th>\n",
       "      <th>minDist</th>\n",
       "      <th>maxDist</th>\n",
       "      <th>meanDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>1.291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793762</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>3.472</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>0.035823</td>\n",
       "      <td>0.056743</td>\n",
       "      <td>3</td>\n",
       "      <td>21.416977</td>\n",
       "      <td>21.504622</td>\n",
       "      <td>21.248050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.203</td>\n",
       "      <td>1.356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850026</td>\n",
       "      <td>-0.0455</td>\n",
       "      <td>2.639</td>\n",
       "      <td>-3.138</td>\n",
       "      <td>-0.018248</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0</td>\n",
       "      <td>21.848598</td>\n",
       "      <td>21.951837</td>\n",
       "      <td>21.702516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535 -0.129 -0.687  1.291  ...   \n",
       "1  0.776  0.914 -0.494  1.347 -0.867  0.480  0.578 -0.313  0.203  1.356  ...   \n",
       "\n",
       "        mad  median    max    min      skew       sem  cluster_values  \\\n",
       "0  0.793762  0.2175  3.472 -2.628  0.035823  0.056743               3   \n",
       "1  0.850026 -0.0455  2.639 -3.138 -0.018248  0.060466               0   \n",
       "\n",
       "     minDist    maxDist   meanDist  \n",
       "0  21.416977  21.504622  21.248050  \n",
       "1  21.848598  21.951837  21.702516  \n",
       "\n",
       "[2 rows x 312 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fe_2 = feature_engg(test_df.drop(columns=[\"id\"]),test_df.drop(columns=[\"id\"]))\n",
    "test_fe_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6099c59",
   "metadata": {},
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238ea1b",
   "metadata": {},
   "source": [
    "## 4.1 Helper Funtions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36310cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "\n",
    "def modelling(model,model_name,params,X,y,test_data,test_ids,file):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"*\"*100)\n",
    "    print(\"Applying {0}....\".format(model_name))\n",
    "    grid_search = GridSearchCV(estimator=model,param_grid=params,cv=10,n_jobs=-1,scoring=\"roc_auc\")\n",
    "    grid_search.fit(X,y)\n",
    "    print(\"Best Hyper-parameters achieved: \", grid_search.best_params_)\n",
    "    # predicting train values with the best-estimator:\n",
    "    if model_name in [\"logistic_regression\",\"svm\"]:\n",
    "        y_pred = grid_search.best_estimator_.predict_proba(X)[:,1]\n",
    "    else:\n",
    "        y_pred = grid_search.best_estimator_.predict(X)\n",
    "        \n",
    "    score = roc_auc_score(y,y_pred)\n",
    "    print(\"ROC achieved on train set using {0}: \".format(model_name), score)\n",
    "    # predicting test values with the best-estimator\n",
    "    print(\"Predicting on test data and saving the results.\")\n",
    "    if model_name in [\"logistic_regression\",\"svm\"]:\n",
    "        pred  = grid_search.best_estimator_.predict_proba(test_data)[:,1]\n",
    "    else:\n",
    "        pred = grid_search.best_estimator_.predict(test_data)\n",
    "        \n",
    "    submission = pd.DataFrame({'id':test_ids,'target':pred})\n",
    "    submission.to_csv(\"{0}/submission_{1}.csv\".format(file,model_name),index = False)\n",
    "    print(\"DONE!!\")\n",
    "    print(\"*\"*100)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "def apply_models(X,y,test_data,test_ids,file):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # define Models\n",
    "    \n",
    "    ## Lasso Regression\n",
    "    params = {\"alpha\":np.arange(0,1.01,0.01)}\n",
    "    model = linear_model.Lasso()\n",
    "    modelling(model,\"Lasso_Regression\",params,X,y,test_data,test_ids,file)\n",
    "    \n",
    "    \n",
    "    ## Ridge Regression\n",
    "    model = linear_model.Ridge()\n",
    "    modelling(model,\"Ridge_Regression\",params,X,y,test_data,test_ids,file)\n",
    "    \n",
    "    ## Elastic Net Regression\n",
    "    params_en = {\"alpha\":[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0],\n",
    "                \"l1_ratio\":np.arange(0,1.01,0.01)}\n",
    "    model = linear_model.ElasticNet()\n",
    "    modelling(model,\"ElasticNet_Regression\",params_en,X,y,test_data,test_ids,file)\n",
    "    \n",
    "    ## LASSOCV Regression\n",
    "    print(\"*\"*100)\n",
    "    print(\"Applying LASSOCV Regression...\")\n",
    "    model = linear_model.LassoCV(cv=10,n_jobs=-1).fit(X,y)\n",
    "    # predicting train values with the best-estimator:\n",
    "    y_pred = model.predict(X)\n",
    "    score = roc_auc_score(y,y_pred)\n",
    "    print(\"ROC achieved on train set using LASSOCV is: \", score)\n",
    "    # predicting test values with the best-estimator\n",
    "    print(\"Predicting on test data and saving the results.\")\n",
    "    pred  = model.predict(test_data)\n",
    "    submission = pd.DataFrame({'id':test_ids,'target':pred})\n",
    "    submission.to_csv(\"{0}/submission_LASSOCV.csv\".format(file),index = False)\n",
    "    print(\"DONE!!\")\n",
    "    print(\"*\"*100)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    ## LARSCV Regression\n",
    "    print(\"*\"*100)\n",
    "    print(\"Applying LARSCV Regression...\")\n",
    "    model = linear_model.LarsCV(cv=10,n_jobs=-1).fit(X,y)\n",
    "    # predicting train values with the best-estimator:\n",
    "    y_pred = model.predict(X)\n",
    "    score = roc_auc_score(y,y_pred)\n",
    "    print(\"ROC achieved on train set using LARSCV is: \", score)\n",
    "    # predicting test values with the best-estimator\n",
    "    print(\"Predicting on test data and saving the results.\")\n",
    "    pred  = model.predict(test_data)\n",
    "    submission = pd.DataFrame({'id':test_ids,'target':pred})\n",
    "    submission.to_csv(\"{0}/submission_LARSCV.csv\".format(file),index = False)\n",
    "    print(\"DONE!!\")\n",
    "    print(\"*\"*100)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    ## Bayesian Ridge Regression\n",
    "    print(\"*\"*100)\n",
    "    print(\"Applying Bayesian Ridge Regression...\")\n",
    "    model = linear_model.BayesianRidge().fit(X,y)\n",
    "    # predicting train values with the best-estimator:\n",
    "    y_pred = model.predict(X)\n",
    "    score = roc_auc_score(y,y_pred)\n",
    "    print(\"ROC achieved on train set using bayesian ridge is: \", score)\n",
    "    # predicting test values with the best-estimator\n",
    "    print(\"Predicting on test data and saving the results.\")\n",
    "    pred  = model.predict(test_data)\n",
    "    submission = pd.DataFrame({'id':test_ids,'target':pred})\n",
    "    submission.to_csv(\"{0}/submission_bayesian_ridge.csv\".format(file),index = False)\n",
    "    print(\"DONE!!\")\n",
    "    print(\"*\"*100)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    ## ARD Regression\n",
    "    print(\"*\"*100)\n",
    "    print(\"Applying ARD Regression...\")\n",
    "    model = linear_model.ARDRegression().fit(X,y)\n",
    "    # predicting train values with the best-estimator:\n",
    "    y_pred = model.predict(X)\n",
    "    score = roc_auc_score(y,y_pred)\n",
    "    print(\"ROC achieved on train set using ARD Regression is: \", score)\n",
    "    # predicting test values with the best-estimator\n",
    "    print(\"Predicting on test data and saving the results.\")\n",
    "    pred  = model.predict(test_data)\n",
    "    submission = pd.DataFrame({'id':test_ids,'target':pred})\n",
    "    submission.to_csv(\"{0}/submission_ard_regression.csv\".format(file),index = False)\n",
    "    print(\"DONE!!\")\n",
    "    print(\"*\"*100)\n",
    "    print()\n",
    "    print()\n",
    "    ## Gaussian NB\n",
    "    param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "    }\n",
    "    model = GaussianNB()\n",
    "    modelling(model,\"Gaussian_NB\",param_grid_nb,X,y,test_data,test_ids,file)\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    params_lr = {\"penalty\":[\"l1\",\"l2\"], \"C\":[0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000],\n",
    "                \"class_weight\":[\"balanced\",None]}\n",
    "    lr = LogisticRegression(solver = \"liblinear\")\n",
    "    \n",
    "    modelling(lr,\"logistic_regression\",params_lr,X,y,test_data,test_ids,file)\n",
    "    \n",
    "    ## SVM\n",
    "    params_svc = {\"kernel\":[\"rbf\",\"poly\",\"linear\"], \"C\":[0.000001, 0.00001,0.0001,0.001,0.01,0.1,1,10,100],\n",
    "                 \"class_weight\":[\"balanced\",None]}\n",
    "    svc = SVC()\n",
    "    modelling(svc,\"svc\",params_svc,X,y,test_data,test_ids,file)\n",
    "    \n",
    "    ## huber regressor\n",
    "    \n",
    "    params_huber = {\"epsilon\":[1, 1,35, 1.5, 1.75, 1.9]}\n",
    "    huber = linear_model.HuberRegressor()\n",
    "    modelling(huber,\"huber_regressor\",params_huber,X,y,test_data,test_ids,file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f84733",
   "metadata": {},
   "source": [
    "## 4.2  Modelling on train data wihout any pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8bfe38d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.06}\n",
      "ROC achieved on train set using Lasso_Regression:  0.883888888888889\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.97}\n",
      "ROC achieved on train set using Ridge_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 1.0, 'l1_ratio': 0.03}\n",
      "ROC achieved on train set using ElasticNet_Regression:  0.9839583333333333\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  0.9721527777777779\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.9918055555555555\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 1.0}\n",
      "ROC achieved on train set using Gaussian_NB:  0.965625\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "ROC achieved on train set using logistic_regression:  0.9573611111111111\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 0.1, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "ROC achieved on train set using svc:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 1}\n",
      "ROC achieved on train set using huber_regressor:  0.9996527777777777\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(x,y,test_df.drop(columns=[\"id\"]),test_df.id.values,\"modelling_on_train_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03bbb00",
   "metadata": {},
   "source": [
    "### Results & Oberservation(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec958355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |         0.88        |       0.832        |\n",
      "|      Ridge Regression      |         0.97        |       0.631        |\n",
      "|   ElasticNet Regression    |         0.98        |       0.827        |\n",
      "|     LASSOCV regression     |         0.97        |       0.845        |\n",
      "|           LARSCV           |         0.99        |        0.83        |\n",
      "| Bayesian Ridge regression  |         1.0         |        0.74        |\n",
      "|       ARD regression       |         1.0         |        0.64        |\n",
      "|        Guassian NB         |         1.0         |        0.66        |\n",
      "|    Logistic regression     |         0.95        |       0.843        |\n",
      "|            SVC             |         1.0         |        0.66        |\n",
      "|      huber_regressor       |         0.99        |       0.643        |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "x.add_row([\"Lasso Regression\", 0.88,0.832])\n",
    "x.add_row([\"Ridge Regression\", 0.97,0.631])\n",
    "x.add_row([\"ElasticNet Regression\", 0.98,0.827])\n",
    "x.add_row([\"LASSOCV regression\", 0.97, 0.845])\n",
    "x.add_row([\"LARSCV\",0.99,0.83])\n",
    "x.add_row([\"Bayesian Ridge regression \", 1.0, 0.74])\n",
    "x.add_row([\"ARD regression\", 1.0, 0.64])\n",
    "x.add_row([\"Guassian NB\", 1.0, 0.66])\n",
    "x.add_row([\"Logistic regression\", 0.95, 0.843])\n",
    "\n",
    "x.add_row([\"SVC\", 1.0, 0.66])\n",
    "x.add_row([\"huber_regressor\", 0.99, 0.643])\n",
    "\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17401d6",
   "metadata": {},
   "source": [
    "- Best roc-auc score achieved by **LASSOCV : 0.845** and **logistic regression: 0.843**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64f9099",
   "metadata": {},
   "source": [
    "## 4.3 Modelling on FE data with computing statistics on 1- feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "effa6344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.03}\n",
      "ROC achieved on train set using Lasso_Regression:  0.981388888888889\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.98}\n",
      "ROC achieved on train set using Ridge_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.1, 'l1_ratio': 0.09}\n",
      "ROC achieved on train set using ElasticNet_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  0.9656944444444444\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.9482638888888889\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 1.0}\n",
      "ROC achieved on train set using Gaussian_NB:  0.9625\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "ROC achieved on train set using logistic_regression:  0.960625\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 0.1, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "ROC achieved on train set using svc:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 1}\n",
      "ROC achieved on train set using huber_regressor:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(fe_1,y,test_fe_1,test_df.id.values,\"modelling_on_fe_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79fd692",
   "metadata": {},
   "source": [
    "### Results & Observation(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c16f1fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |        0.981        |       0.843        |\n",
      "|      Ridge Regression      |         0.98        |        0.63        |\n",
      "|   ElasticNet Regression    |         1.0         |        0.77        |\n",
      "|     LASSOCV regression     |         0.96        |       0.845        |\n",
      "|           LARSCV           |         0.94        |       0.847        |\n",
      "| Bayesian Ridge regression  |         1.0         |        0.74        |\n",
      "|       ARD regression       |         1.0         |       0.634        |\n",
      "|        Guassian NB         |         0.96        |        0.66        |\n",
      "|    Logistic regression     |         0.96        |       0.846        |\n",
      "|            SVC             |         1.0         |        0.66        |\n",
      "|      huber_regressor       |         1.0         |       0.695        |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 0.981,0.843])\n",
    "table.add_row([\"Ridge Regression\", 0.98,0.630])\n",
    "table.add_row([\"ElasticNet Regression\", 1.0,0.77])\n",
    "table.add_row([\"LASSOCV regression\", 0.96, 0.845])\n",
    "table.add_row([\"LARSCV\",0.94,0.847])\n",
    "table.add_row([\"Bayesian Ridge regression \", 1.0, 0.74])\n",
    "table.add_row([\"ARD regression\", 1.0, 0.634])\n",
    "table.add_row([\"Guassian NB\", 0.96, 0.66])\n",
    "table.add_row([\"Logistic regression\", 0.96, 0.846])\n",
    "table.add_row([\"SVC\", 1.0, 0.66])\n",
    "table.add_row([\"huber_regressor\", 1.0, 0.695])\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ea96f",
   "metadata": {},
   "source": [
    "- Result is almost same as previous modelling results.\n",
    "- Best roc score achived by **LARSCV: 0.847** on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9433742",
   "metadata": {},
   "source": [
    "## 4.4 Modelling on FE data with computing statistics on whole train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "17a59270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.04}\n",
      "ROC achieved on train set using Lasso_Regression:  0.9570833333333334\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 1.0}\n",
      "ROC achieved on train set using Ridge_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 1.0, 'l1_ratio': 0.03}\n",
      "ROC achieved on train set using ElasticNet_Regression:  0.9834722222222223\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  0.9723611111111111\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.9554166666666668\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 0.657933224657568}\n",
      "ROC achieved on train set using Gaussian_NB:  0.96875\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "ROC achieved on train set using logistic_regression:  0.9556944444444445\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 0.1, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "ROC achieved on train set using svc:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 1}\n",
      "ROC achieved on train set using huber_regressor:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(fe_2,y,test_fe_2,test_df.id.values,\"modelling_on_fe_2_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "58979193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |         0.95        |       0.847        |\n",
      "|      Ridge Regression      |         1.0         |       0.633        |\n",
      "|   ElasticNet Regression    |         0.98        |       0.827        |\n",
      "|     LASSOCV regression     |         0.97        |       0.845        |\n",
      "|           LARSCV           |         0.95        |       0.831        |\n",
      "| Bayesian Ridge regression  |         1.0         |       0.745        |\n",
      "|       ARD regression       |         1.0         |        0.62        |\n",
      "|        Guassian NB         |         0.96        |        0.66        |\n",
      "|    Logistic regression     |         0.95        |       0.848        |\n",
      "|            SVC             |         1.0         |        0.67        |\n",
      "|      huber_regressor       |         1.0         |        0.7         |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 0.95,0.847])\n",
    "table.add_row([\"Ridge Regression\", 1.0,0.633])\n",
    "table.add_row([\"ElasticNet Regression\", 0.98,0.827])\n",
    "table.add_row([\"LASSOCV regression\", 0.97, 0.845])\n",
    "table.add_row([\"LARSCV\",0.95,0.831])\n",
    "table.add_row([\"Bayesian Ridge regression \", 1.0, 0.745])\n",
    "table.add_row([\"ARD regression\", 1.0, 0.62])\n",
    "table.add_row([\"Guassian NB\", 0.96, 0.66])\n",
    "table.add_row([\"Logistic regression\", 0.95, 0.848])\n",
    "table.add_row([\"SVC\", 1.0, 0.67])\n",
    "table.add_row([\"huber_regressor\", 1.0, 0.70])\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77af889",
   "metadata": {},
   "source": [
    "- Results are almost same, no improvment is visible.\n",
    "- Best AUROC score achieved by **Logisitic Regression: 0.848** on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c674eb1",
   "metadata": {},
   "source": [
    "## 4.5 Modelling on train data + oversampling minority class using SMOTE technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a188fcac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1.0: 160, 0.0: 160})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res,y_res = sm.fit_resample(x, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d9584a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Lasso_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Ridge_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 1e-05, 'l1_ratio': 0.0}\n",
      "ROC achieved on train set using ElasticNet_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.994921875\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 1.0}\n",
      "ROC achieved on train set using Gaussian_NB:  0.50625\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "ROC achieved on train set using logistic_regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 10, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "ROC achieved on train set using svc:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 1}\n",
      "ROC achieved on train set using huber_regressor:  0.9996484375\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(X_res,y_res,test_df.drop(columns=[\"id\"]),test_df.id.values,\"modelling_on_train_oversampling_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "25cec3ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |         1.0         |        0.62        |\n",
      "|      Ridge Regression      |         1.0         |        0.62        |\n",
      "|   ElasticNet Regression    |         1.0         |        0.62        |\n",
      "|     LASSOCV regression     |         1.0         |        0.77        |\n",
      "|           LARSCV           |         0.99        |        0.81        |\n",
      "| Bayesian Ridge regression  |         1.0         |        0.62        |\n",
      "|       ARD regression       |         1.0         |        0.61        |\n",
      "|        Guassian NB         |         0.5         |        0.5         |\n",
      "|    Logistic regression     |         1.0         |        0.72        |\n",
      "|            SVC             |         1.0         |        0.61        |\n",
      "|      huber_regressor       |         0.99        |        0.65        |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 1.0,0.62])\n",
    "table.add_row([\"Ridge Regression\", 1.0,0.62])\n",
    "table.add_row([\"ElasticNet Regression\", 1.0,0.62])\n",
    "table.add_row([\"LASSOCV regression\", 1.0, 0.77])\n",
    "table.add_row([\"LARSCV\",0.99,0.81])\n",
    "table.add_row([\"Bayesian Ridge regression \", 1.0, 0.62])\n",
    "table.add_row([\"ARD regression\", 1.0, 0.61])\n",
    "table.add_row([\"Guassian NB\", 0.50, 0.50])\n",
    "table.add_row([\"Logistic regression\", 1.0, 0.72])\n",
    "table.add_row([\"SVC\", 1.0, 0.61])\n",
    "table.add_row([\"huber_regressor\", 0.99, 0.65])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70058f74",
   "metadata": {},
   "source": [
    "- AUROC score has dropped drastically for all the models.\n",
    "- So, using SMOTE oversampling technique does not yield good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ec2e1a",
   "metadata": {},
   "source": [
    "## 4.5 Modelling on train data + oversampling minority class using BorderLine SMOTE technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94dac053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1.0: 160, 0.0: 160})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE \n",
    "from collections import Counter\n",
    "\n",
    "sm = BorderlineSMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(x, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687faa96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Lasso_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Ridge_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 1e-05, 'l1_ratio': 0.0}\n",
      "ROC achieved on train set using ElasticNet_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.99484375\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 0.8111308307896871}\n",
      "ROC achieved on train set using Gaussian_NB:  0.525\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 1000, 'class_weight': None, 'penalty': 'l1'}\n",
      "ROC achieved on train set using logistic_regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 1, 'class_weight': 'balanced', 'kernel': 'poly'}\n",
      "ROC achieved on train set using svc:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 1}\n",
      "ROC achieved on train set using huber_regressor:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(X_res,y_res,test_df.drop(columns=[\"id\"]),test_df.id.values,\"modelling_on_train_oversampling_borderline_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3264b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 1.0,0.62])\n",
    "table.add_row([\"Ridge Regression\", 1.0,0.62])\n",
    "table.add_row([\"ElasticNet Regression\", 1.0,0.62])\n",
    "table.add_row([\"LASSOCV regression\", 1.0, 0.77])\n",
    "table.add_row([\"LARSCV\",0.99,0.825])\n",
    "table.add_row([\"Bayesian Ridge regression \", 1.0, 0.62])\n",
    "table.add_row([\"ARD regression\", 1.0, 0.61])\n",
    "table.add_row([\"Guassian NB\", 0.50, 0.50])\n",
    "table.add_row([\"Logistic regression\", 1.0, 0.72])\n",
    "table.add_row([\"SVC\", 1.0, 0.61])\n",
    "table.add_row([\"huber_regressor\", 0.99, 0.65])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9498a8",
   "metadata": {},
   "source": [
    "- All models perform bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ed14f",
   "metadata": {},
   "source": [
    "## 4.6 Modelling on train data + Under-Sampling using Neighbourhood Cleaning Rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5657de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0.0: 90, 1.0: 81})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "# define the undersampling method\n",
    "undersample = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)\n",
    "# transform the dataset\n",
    "x_res, y_res = undersample.fit_resample(x, y)\n",
    "# summarize the new class distribution\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b908325b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.02}\n",
      "ROC achieved on train set using Lasso_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Ridge_Regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 1.0, 'l1_ratio': 0.03}\n",
      "ROC achieved on train set using ElasticNet_Regression:  0.9990397805212621\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.9997256515775034\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 1.0}\n",
      "ROC achieved on train set using Gaussian_NB:  0.962962962962963\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 0.0001, 'class_weight': None, 'penalty': 'l2'}\n",
      "ROC achieved on train set using logistic_regression:  0.9976680384087792\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 0.1, 'class_weight': None, 'kernel': 'rbf'}\n",
      "ROC achieved on train set using svc:  0.5\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 35}\n",
      "ROC achieved on train set using huber_regressor:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(x_res,y_res,test_df.drop(columns=[\"id\"]),test_df.id.values,\"modelling_on_train_undersampling_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9793a4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |         1.0         |        0.71        |\n",
      "|      Ridge Regression      |         1.0         |       0.652        |\n",
      "|   ElasticNet Regression    |         1.0         |        0.62        |\n",
      "|     LASSOCV regression     |         1.0         |       0.784        |\n",
      "|           LARSCV           |         0.99        |       0.773        |\n",
      "| Bayesian Ridge regression  |         1.0         |        0.65        |\n",
      "|       ARD regression       |         1.0         |        0.64        |\n",
      "|        Guassian NB         |         0.5         |        0.79        |\n",
      "|    Logistic regression     |         1.0         |        0.71        |\n",
      "|            SVC             |         1.0         |        0.5         |\n",
      "|      huber_regressor       |         0.99        |       0.581        |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 1.0,0.71])\n",
    "table.add_row([\"Ridge Regression\", 1.0,0.652])\n",
    "table.add_row([\"ElasticNet Regression\", 1.0,0.62])\n",
    "table.add_row([\"LASSOCV regression\", 1.0, 0.784])\n",
    "table.add_row([\"LARSCV\",0.99,0.773])\n",
    "table.add_row([\"Bayesian Ridge regression \", 1.0, 0.65])\n",
    "table.add_row([\"ARD regression\", 1.0, 0.64])\n",
    "table.add_row([\"Guassian NB\", 0.50, 0.79])\n",
    "table.add_row([\"Logistic regression\", 1.0, 0.71])\n",
    "table.add_row([\"SVC\", 1.0, 0.50])\n",
    "table.add_row([\"huber_regressor\", 0.99, 0.581])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93fb0d",
   "metadata": {},
   "source": [
    "- Results get worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2e165",
   "metadata": {},
   "source": [
    "## 4.7 Modelling on data with Lasso feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9bacc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper-parameters achieved:  {'alpha': 0.06}\n"
     ]
    }
   ],
   "source": [
    "params = {\"alpha\":np.arange(0,1.01,0.01)}\n",
    "\n",
    "model = linear_model.Lasso()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model,param_grid=params,cv=10,n_jobs=-1,scoring=\"roc_auc\")\n",
    "grid_search.fit(x,y)\n",
    "\n",
    "print(\"Best Hyper-parameters achieved: \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d973baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features discarded with coffecients of Lasso Regression equals 0:  288\n",
      "****************************************************************************************************\n",
      "Number of Important features with coffecients of Lasso Regression greater than 0:  12\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficients = grid_search.best_estimator_.coef_\n",
    "\n",
    "# the importance of a feature is it's absolute value of it's coffecient.\n",
    "\n",
    "importance = np.abs(coefficients)\n",
    "imp_features = np.array(x.columns)[importance > 0]\n",
    "discarded_features = np.array(x.columns)[importance == 0]\n",
    "\n",
    "print(\"Number of features discarded with coffecients of Lasso Regression equals 0: \", len(discarded_features))\n",
    "print(\"*\"*100)\n",
    "print(\"Number of Important features with coffecients of Lasso Regression greater than 0: \", len(imp_features))\n",
    "print(\"*\"*100)\n",
    "\n",
    "\n",
    "feat_importances = pd.Series(importance[importance > 0],imp_features)\n",
    "feat_importances.plot(kind=\"barh\")\n",
    "plt.title(\"Bar plot between features and coffecients of Lasso Regression greater than 0.\")\n",
    "plt.xlabel(\"Coffecient of Lasso Regression greater than zero\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9761f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the important features given by Lasso Regression.\n",
    "np.save(\"important_fea\",imp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d6a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['16', '33', '65', '73', '80', '91', '117', '133', '189', '199',\n",
       "       '217', '295'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"important_fea.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f84476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data after selecting the important features: (250, 12)\n",
      "Shape of test data after selecting the important features: (19750, 12)\n"
     ]
    }
   ],
   "source": [
    "# selecting the important features from the train data\n",
    "\n",
    "x_fea_imp_using_lasso = x.loc[:,imp_features]\n",
    "print(\"Shape of train data after selecting the important features:\", x_fea_imp_using_lasso.shape)\n",
    "\n",
    "# selecting the important features from the train data\n",
    "\n",
    "test_fea_imp_using_lasso = test_df.drop(columns=[\"id\"]).loc[:,imp_features]\n",
    "print(\"Shape of test data after selecting the important features:\", test_fea_imp_using_lasso.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f8bb273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Lasso_Regression:  0.9184722222222222\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Ridge_Regression:  0.9184722222222222\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.01, 'l1_ratio': 0.16}\n",
      "ROC achieved on train set using ElasticNet_Regression:  0.9184027777777778\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  0.9182638888888889\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.9184722222222222\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  0.9177777777777778\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  0.91875\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 1.0}\n",
      "ROC achieved on train set using Gaussian_NB:  0.7541666666666668\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "ROC achieved on train set using logistic_regression:  0.9194444444444445\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 0.001, 'class_weight': None, 'kernel': 'rbf'}\n",
      "ROC achieved on train set using svc:  0.5\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 35}\n",
      "ROC achieved on train set using huber_regressor:  0.9184722222222222\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(x_fea_imp_using_lasso,y,test_fea_imp_using_lasso,test_df.id.values,\"modelling_on_fea_imp_using_lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05731e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |         0.91        |       0.848        |\n",
      "|      Ridge Regression      |         0.91        |       0.848        |\n",
      "|   ElasticNet Regression    |         0.91        |       0.848        |\n",
      "|     LASSOCV regression     |         0.91        |       0.848        |\n",
      "|           LARSCV           |         0.91        |       0.848        |\n",
      "| Bayesian Ridge regression  |         0.91        |       0.847        |\n",
      "|       ARD regression       |         0.91        |       0.852        |\n",
      "|        Guassian NB         |         0.75        |       0.672        |\n",
      "|    Logistic regression     |         0.91        |       0.845        |\n",
      "|            SVC             |         0.5         |        0.5         |\n",
      "|      huber_regressor       |         0.91        |       0.848        |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 0.91,0.848])\n",
    "table.add_row([\"Ridge Regression\", 0.91,0.848])\n",
    "table.add_row([\"ElasticNet Regression\", 0.91,0.848])\n",
    "table.add_row([\"LASSOCV regression\", 0.91, 0.848])\n",
    "table.add_row([\"LARSCV\",0.91,0.848])\n",
    "table.add_row([\"Bayesian Ridge regression \", 0.91, 0.847])\n",
    "table.add_row([\"ARD regression\", 0.91, 0.852])\n",
    "table.add_row([\"Guassian NB\", 0.75, 0.672])\n",
    "table.add_row([\"Logistic regression\", 0.91, 0.845])\n",
    "table.add_row([\"SVC\", 0.5, 0.50])\n",
    "table.add_row([\"huber_regressor\", 0.91, 0.848])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4816a62",
   "metadata": {},
   "source": [
    "- Feature Importance with Lasso regressor has worked really as it has improved the roc-auc score for all the models.\n",
    "- The best au-roc score achieved by **ARD regression:0.852** on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8251ba7",
   "metadata": {},
   "source": [
    "## 4.8 Modelling on data with RFE feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9173dead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=10,\n",
       "      estimator=LogisticRegression(C=0.1, penalty='l1', solver='liblinear'),\n",
       "      scoring='roc_auc')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# using logistic regression as base estimator\n",
    "\n",
    "params_lr = {\"penalty\":[\"l1\",\"l2\"], \"C\":[0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000],\n",
    "            \"class_weight\":[\"balanced\",None]}\n",
    "lr = LogisticRegression(solver = \"liblinear\")\n",
    "\n",
    "grid_search = GridSearchCV(lr,param_grid=params_lr,cv=10,n_jobs=-1,scoring=\"roc_auc\").fit(x,y)\n",
    "\n",
    "rfecv = RFECV(estimator=grid_search.best_estimator_, step=1, cv=10, scoring='roc_auc')\n",
    "rfecv.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4fc13d55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features, as per decided by RFECV: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Optimal number of features, as per decided by RFECV: {}'.format(rfecv.n_features_))\n",
    "\n",
    "imp_features = np.where(rfecv.support_==True)[0]\n",
    "\n",
    "importance = np.abs(rfecv.estimator_.coef_[0])\n",
    "\n",
    "feat_importances = pd.Series(importance,imp_features)\n",
    "\n",
    "feat_importances.plot(kind=\"barh\")\n",
    "plt.title(\"Bar plot between features and coefficients given by LR.\")\n",
    "plt.xlabel(\"Coffecient of logistic regression\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2fd20123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data after selecting the important features: (250, 6)\n",
      "Shape of test data after selecting the important features: (19750, 6)\n"
     ]
    }
   ],
   "source": [
    "x_fea_imp_using_rfe_lr = x.iloc[:,list(np.where(rfecv.support_==True)[0])]\n",
    "\n",
    "print(\"Shape of train data after selecting the important features:\", x_fea_imp_using_rfe_lr.shape)\n",
    "\n",
    "test_fea_imp_using_rfe_lr = test_df.drop(columns=[\"id\"]).iloc[:,list(np.where(rfecv.support_==True)[0])]\n",
    "print(\"Shape of test data after selecting the important features:\", test_fea_imp_using_rfe_lr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bc223111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Lasso_Regression:  0.8725694444444444\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Ridge_Regression:  0.8725694444444444\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "ROC achieved on train set using ElasticNet_Regression:  0.8716666666666667\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  0.8722222222222223\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.8725694444444444\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  0.8720833333333334\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  0.8725\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 1.0}\n",
      "ROC achieved on train set using Gaussian_NB:  0.684375\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "ROC achieved on train set using logistic_regression:  0.8735416666666667\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 1, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "ROC achieved on train set using svc:  0.8559027777777778\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 1.5}\n",
      "ROC achieved on train set using huber_regressor:  0.8715277777777777\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(x_fea_imp_using_rfe_lr,y,test_fea_imp_using_rfe_lr,test_df.id.values,\"modelling_on_fea_imp_using_rfe_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a12ea23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |         0.87        |       0.835        |\n",
      "|      Ridge Regression      |         0.87        |       0.835        |\n",
      "|   ElasticNet Regression    |         0.87        |       0.835        |\n",
      "|     LASSOCV regression     |         0.87        |       0.835        |\n",
      "|           LARSCV           |         0.87        |       0.835        |\n",
      "| Bayesian Ridge regression  |         0.87        |       0.835        |\n",
      "|       ARD regression       |         0.87        |       0.836        |\n",
      "|        Guassian NB         |         0.68        |       0.672        |\n",
      "|    Logistic regression     |         0.87        |       0.635        |\n",
      "|            SVC             |         0.85        |        0.73        |\n",
      "|      huber_regressor       |         0.87        |       0.835        |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 0.87,0.835])\n",
    "table.add_row([\"Ridge Regression\", 0.87,0.835])\n",
    "table.add_row([\"ElasticNet Regression\", 0.87,0.835])\n",
    "table.add_row([\"LASSOCV regression\", 0.87, 0.835])\n",
    "table.add_row([\"LARSCV\",0.87,0.835])\n",
    "table.add_row([\"Bayesian Ridge regression \", 0.87, 0.835])\n",
    "table.add_row([\"ARD regression\", 0.87, 0.836])\n",
    "table.add_row([\"Guassian NB\", 0.68, 0.672])\n",
    "table.add_row([\"Logistic regression\", 0.87, 0.635])\n",
    "table.add_row([\"SVC\", 0.85, 0.73])\n",
    "table.add_row([\"huber_regressor\", 0.87, 0.835])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d404702b",
   "metadata": {},
   "source": [
    "- it has dropped the score for all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a83ad",
   "metadata": {},
   "source": [
    "## 4.9 Modelling on data with Forward feature selection feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "240fdaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(estimator=LogisticRegression(), n_jobs=-1,\n",
       "                          scoring='roc_auc')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# using logistic regression as base estimator\n",
    "\n",
    "sfs = SequentialFeatureSelector(linear_model.LogisticRegression(),n_jobs=-1,scoring=\"roc_auc\")\n",
    "sfs.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "17e2a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features, as per selected by Sequential feature selector : 150\n",
      "****************************************************************************************************\n",
      "Shape of train data after selecting the important features: (250, 150)\n",
      "Shape of test data after selecting the important features: (19750, 150)\n"
     ]
    }
   ],
   "source": [
    "print('Optimal number of features, as per selected by Sequential feature selector : {}'.format(sfs.n_features_to_select_))\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "x_fea_imp_using_ffs = x.loc[:,(x.columns[sfs.support_==True])]\n",
    "\n",
    "print(\"Shape of train data after selecting the important features:\", x_fea_imp_using_ffs.shape)\n",
    "\n",
    "test_fea_imp_using_ffs = test_df.drop(columns=[\"id\"]).loc[:,(x.columns[sfs.support_==True])]\n",
    "print(\"Shape of test data after selecting the important features:\", test_fea_imp_using_ffs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ceb80b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.05}\n",
      "ROC achieved on train set using Lasso_Regression:  0.9015972222222223\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.8300000000000001}\n",
      "ROC achieved on train set using Ridge_Regression:  0.9997916666666667\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.1, 'l1_ratio': 0.49}\n",
      "ROC achieved on train set using ElasticNet_Regression:  0.903263888888889\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  0.9752083333333333\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.9772916666666667\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  0.991111111111111\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  0.9891666666666666\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 1.0}\n",
      "ROC achieved on train set using Gaussian_NB:  0.8979166666666667\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "ROC achieved on train set using logistic_regression:  1.0\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 0.1, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "ROC achieved on train set using svc:  0.996875\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 1}\n",
      "ROC achieved on train set using huber_regressor:  0.9735416666666667\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(x_fea_imp_using_ffs,y,test_fea_imp_using_ffs,test_df.id.values,\"modelling_on_fea_imp_using_ffs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "91cd9393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |         0.9         |       0.844        |\n",
      "|      Ridge Regression      |         0.99        |       0.715        |\n",
      "|   ElasticNet Regression    |         0.9         |       0.844        |\n",
      "|     LASSOCV regression     |         0.97        |       0.842        |\n",
      "|           LARSCV           |         0.97        |       0.839        |\n",
      "| Bayesian Ridge regression  |         0.99        |       0.773        |\n",
      "|       ARD regression       |         0.98        |       0.801        |\n",
      "|        Guassian NB         |         0.89        |        0.64        |\n",
      "|    Logistic regression     |         1.0         |        0.75        |\n",
      "|            SVC             |         0.99        |       0.676        |\n",
      "|      huber_regressor       |         0.97        |        0.72        |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 0.90,0.844])\n",
    "table.add_row([\"Ridge Regression\", 0.99,0.715])\n",
    "table.add_row([\"ElasticNet Regression\", 0.90,0.844])\n",
    "table.add_row([\"LASSOCV regression\", 0.97, 0.842])\n",
    "table.add_row([\"LARSCV\",0.97,0.839])\n",
    "table.add_row([\"Bayesian Ridge regression \", 0.99, 0.773])\n",
    "table.add_row([\"ARD regression\", 0.98, 0.801])\n",
    "table.add_row([\"Guassian NB\", 0.89, 0.64])\n",
    "table.add_row([\"Logistic regression\", 1.0, 0.75])\n",
    "table.add_row([\"SVC\", 0.99, 0.676])\n",
    "table.add_row([\"huber_regressor\", 0.97, 0.72])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705b108",
   "metadata": {},
   "source": [
    "- Perform okayish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572412e8",
   "metadata": {},
   "source": [
    "## 5. Psedo-labelling | Semi-Supervised Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5644d5cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## define Logistic Regression\n",
    "params_lr = {\"penalty\":[\"l1\",\"l2\"], \"C\":[0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000],\n",
    "            \"class_weight\":[\"balanced\",None]}\n",
    "\n",
    "lr = LogisticRegression(solver = \"liblinear\")\n",
    "\n",
    "grid_search = GridSearchCV(lr,param_grid=params_lr,cv=10,n_jobs=-1,scoring=\"roc_auc\").fit(x_fea_imp_using_lasso,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75a193d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples:  3950\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      "(19750, 12)\n",
      "Shape of augmented data with sampling rate 0.2:  (4200, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_rate = 0.2\n",
    "num_of_samples = int(len(test_fea_imp_using_lasso) * sample_rate)\n",
    "print(\"Number of Samples: \",num_of_samples)\n",
    "\n",
    "# Train the model and creat the pseudo-labels\n",
    "#grid_search.best_estimator_.fit(x_fea_imp_using_lasso,y)\n",
    "model = linear_model.ARDRegression().fit(x_fea_imp_using_lasso,y)\n",
    "#pseudo_labels = grid_search.best_estimator_.predict(test_fea_imp_using_lasso)\n",
    "pseudo_labels = model.predict(test_fea_imp_using_lasso)\n",
    "\n",
    "pseudo_labels[pseudo_labels >=0.5] = 1\n",
    "pseudo_labels[pseudo_labels <0.5] = 0\n",
    "print(pseudo_labels[:10])\n",
    "\n",
    "# Add the pseudo-labels to the test set\n",
    "pseudo_data = test_fea_imp_using_lasso.copy(deep=True)\n",
    "print(pseudo_data.shape)\n",
    "pseudo_data[\"target\"] = pseudo_labels\n",
    "\n",
    "\n",
    "# Take a subset of the test set with pseudo-labels and append in onto\n",
    "# the training set\n",
    "sampled_pseudo_data = pseudo_data.sample(n=num_of_samples)\n",
    "temp_train = pd.concat([x_fea_imp_using_lasso, y], axis=1)\n",
    "augemented_train = pd.concat([sampled_pseudo_data, temp_train])\n",
    "\n",
    "print(\"Shape of augmented data with sampling rate {}: \".format(sample_rate),augemented_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "149f7445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Applying Lasso_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Lasso_Regression:  0.9934496622382316\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Ridge_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 0.0}\n",
      "ROC achieved on train set using Ridge_Regression:  0.9934496622382316\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ElasticNet_Regression....\n",
      "Best Hyper-parameters achieved:  {'alpha': 1.0, 'l1_ratio': 0.0}\n",
      "ROC achieved on train set using ElasticNet_Regression:  0.9935193496361123\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LASSOCV Regression...\n",
      "ROC achieved on train set using LASSOCV is:  0.9934474411259485\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying LARSCV Regression...\n",
      "ROC achieved on train set using LARSCV is:  0.9934496622382316\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Bayesian Ridge Regression...\n",
      "ROC achieved on train set using bayesian ridge is:  0.9934499398772669\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying ARD Regression...\n",
      "ROC achieved on train set using ARD Regression is:  0.9934432765404176\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying Gaussian_NB....\n",
      "Best Hyper-parameters achieved:  {'var_smoothing': 1.0}\n",
      "ROC achieved on train set using Gaussian_NB:  0.6424642241279983\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying logistic_regression....\n",
      "Best Hyper-parameters achieved:  {'C': 1000, 'class_weight': None, 'penalty': 'l2'}\n",
      "ROC achieved on train set using logistic_regression:  0.9937867160271854\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying svc....\n",
      "Best Hyper-parameters achieved:  {'C': 100, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "ROC achieved on train set using svc:  0.9769220881009739\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Applying huber_regressor....\n",
      "Best Hyper-parameters achieved:  {'epsilon': 35}\n",
      "ROC achieved on train set using huber_regressor:  0.9934496622382316\n",
      "Predicting on test data and saving the results.\n",
      "DONE!!\n",
      "****************************************************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apply_models(augemented_train.drop(columns=[\"target\"]),augemented_train.target.values,test_fea_imp_using_lasso,\n",
    "             test_df.id.values,\"modelling_on_data_using_psedo_labelling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf1dbe26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------+--------------------+\n",
      "|           Model            | train_roc_auc_score | test_roc_auc_score |\n",
      "+----------------------------+---------------------+--------------------+\n",
      "|      Lasso Regression      |         0.9         |       0.851        |\n",
      "|      Ridge Regression      |         0.99        |       0.851        |\n",
      "|   ElasticNet Regression    |         0.9         |       0.851        |\n",
      "|     LASSOCV regression     |         0.97        |       0.851        |\n",
      "|           LARSCV           |         0.97        |       0.851        |\n",
      "| Bayesian Ridge regression  |         0.99        |       0.851        |\n",
      "|       ARD regression       |         0.98        |       0.852        |\n",
      "|        Guassian NB         |         0.89        |       0.603        |\n",
      "|    Logistic regression     |         1.0         |       0.852        |\n",
      "|            SVC             |         0.99        |       0.747        |\n",
      "|      huber_regressor       |         0.97        |       0.851        |\n",
      "+----------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable()\n",
    "\n",
    "table.field_names = [\"Model\", \"train_roc_auc_score\", \"test_roc_auc_score\"]\n",
    "table.add_row([\"Lasso Regression\", 0.90,0.851])\n",
    "table.add_row([\"Ridge Regression\", 0.99,0.851])\n",
    "table.add_row([\"ElasticNet Regression\", 0.90,0.851])\n",
    "table.add_row([\"LASSOCV regression\", 0.97, 0.851])\n",
    "table.add_row([\"LARSCV\",0.97,0.851])\n",
    "table.add_row([\"Bayesian Ridge regression \", 0.99, 0.851])\n",
    "table.add_row([\"ARD regression\", 0.98, 0.852])\n",
    "table.add_row([\"Guassian NB\", 0.89, 0.603])\n",
    "table.add_row([\"Logistic regression\", 1.0, 0.852])\n",
    "table.add_row([\"SVC\", 0.99, 0.747])\n",
    "table.add_row([\"huber_regressor\", 0.97, 0.851])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08635791",
   "metadata": {},
   "source": [
    "- It has improved almost all models a bit. But, still the best roc score achieved is **0.852**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfbb6ba",
   "metadata": {},
   "source": [
    "# 6. Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315f50e",
   "metadata": {},
   "source": [
    "- Best ROC-AUC score achieved **0.852** on test set by  ARD regressor using Lasso Feature Importance.\n",
    "- This best score is in **top 5% of the kaggle leaderboard score.**\n",
    "\n",
    "![alt text](kaggle_score.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5055b0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving the best model\n",
    "import pickle\n",
    "\n",
    "model = linear_model.ARDRegression().fit(x_fea_imp_using_lasso,y)\n",
    "\n",
    "\n",
    "pickle.dump(model, open(\"best_model\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31ebfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
